<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome file</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="infrastruktur-team">Infrastruktur-Team</h1>
<h2 id="todo-bis-09.10.---1500-uhr">TODO bis 09.10. - 15:00 Uhr</h2>
<h3 id="docker-einarbeiten">Docker einarbeiten</h3>
<h3 id="framework-kafka">Framework Kafka</h3>
<p><a href="https://ipt.ch/apache-kafka-und-was-es-mit-dem-hype-auf-sich-hat/">https://ipt.ch/apache-kafka-und-was-es-mit-dem-hype-auf-sich-hat/</a><br>
<strong>Vorteile</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">
</code></pre>
<p><strong>Nachteile</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">
</code></pre>
<p><strong>Schnittstellen</strong></p>
<ul>
<li>Alles in Java, PHP, Python, C/C++, Ruby, Perl oder Go</li>
<li><strong>Kafka Producer</strong>: Das Producer-API ermöglicht Anwendungen, Datenströme an den bzw. die Broker eines Apache-Cluster zu senden, um diese zu kategorisieren und zu speichern (in den bereits erwähnten Topics).</li>
<li><strong>Kafka Consumer</strong>: Über die Consumer-API erhalten Apache-Kafka-Consumer Lesezugriff auf Daten, die in den Topics des Clusters gespeichert sind.</li>
<li><strong>Kafka Streams</strong>: Das Streams-API erlaubt es einer Anwendung, als Stream-Prozessor zu fungieren, um eingehende Datenströme in ausgehende Datenströme umzuwandeln.</li>
<li><strong>Kafka Connect</strong>: Dank des Connect-API ist es möglich, wiederverwendbare Producer und Consumer einzurichten, die Kafka-Topics mit existierenden Applikationen oder Datenbanksystemen verbinden.</li>
<li><strong>Kafka AdminClient</strong>: Die Schnittstelle „AdminClient“ dient der einfachen Administration und Inspektion des Kafka-Clusters.</li>
</ul>
<p><strong>Ports</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">Default: 9092 (server.properties)
Im Cluster: 2888, 3888
	- ClientConnection: 2181
	- FollowerConnection: 2888 (if leader)
	- else &amp; other connections: 3888

</code></pre>
<p><strong>Datenanbindung</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">
</code></pre>
<p><strong>Wie testet man?</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">
</code></pre>
<h3 id="framework-spark">Framework Spark</h3>
<p><strong>Vorteile</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">- In-Memory Verarbeitung -&gt; Schnelle Datenverarbeitung
- Nahe-Echtzeitverarbeitung
- Maschinelles Lernen
- Datensätze verknüpfbar
- Graph-Verarbeitung möglich
- Schnelle iterative Verarbeitung, da RDDs verteilt in-memory verarbeitet werden können
</code></pre>
<p><strong>Nachteile</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">- Weniger Daten im Vgl. zu Hadoop verarbeitbar wegen In-Memory
- Teuerer im Gegensatz zu z.B. Hadoop
</code></pre>
<p><strong>Schnittstellen</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">Spark-Shell per Scala (Zugriff auf Java-Bibliotheken) oder Python.

</code></pre>
<p><strong>Ports</strong></p>

<table>
<thead>
<tr>
<th>Service</th>
<th>Ports</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spark Standalone Master (RPC)</td>
<td>7077</td>
</tr>
<tr>
<td>Spark Standalone Master (Web UI)</td>
<td>8580, 8980*</td>
</tr>
<tr>
<td>Spark Standalone Worker</td>
<td>8581, 8981*</td>
</tr>
<tr>
<td>Spark Thrift Server</td>
<td>2304</td>
</tr>
<tr>
<td>Spark History Server</td>
<td>18080,18480*</td>
</tr>
<tr>
<td>Spark External Shuffle Service (if yarn shuffle service is enabled)</td>
<td>7337</td>
</tr>
<tr>
<td>CLDB</td>
<td>7222</td>
</tr>
<tr>
<td>ZooKeeper</td>
<td>5181</td>
</tr>
<tr>
<td>Nodes running ResourceManager</td>
<td>8032</td>
</tr>
<tr>
<td>MapR Filesystem Server</td>
<td>5660, 5692</td>
</tr>
</tbody>
</table><p><strong>Datenanbindung</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">Batch: 
	Benötigt: SparkContext, RDD (Resilient Distributed Dataset), Dataset

RDD = verteilte, fehlertolerante Collections in einem Spark Cluster (entweder aus HDFS lesen oder lokal anlegen und verteilen)
</code></pre>
<pre class=" language-java"><code class="prism  language-java">
SparkConf conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
			<span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"Foobar"</span><span class="token punctuation">)</span>
			<span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"[*]local"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
JavaSparkContext sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JavaSparkContext</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>

JavaRDD<span class="token operator">&lt;</span>String<span class="token operator">&gt;</span> text <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">"/tmp/datei.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">long</span> ergebnis <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> line<span class="token punctuation">.</span>count<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
sc<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p><strong>Wie testet man?</strong></p>
<pre class=" language-ssh"><code class="prism  language-ssh">- per Spark Shell: 
	you can examine physical and logical query plans, partitioning strategy and preservation, and the state of your data with many different functions like `toDebugString`, `explain`, `glom`, `show`, `printSchema`, and so on

- integration testing:
	https://stackoverflow.com/questions/43729262/how-to-write-unit-tests-in-spark-2-0
	
</code></pre>
<p><strong>Spark Bibliotheken</strong></p>
<ul>
<li>Spark <strong>Core</strong>: Basisfunktionen und Infrastruktur (Ein-, Ausgabe, Verteilung u.ä.)</li>
<li>Spark <strong>Streaming</strong>: Microbatching-Fähigkeiten zur Stream-Verarbeitung</li>
<li>Spark <strong>SQL</strong>: SQL-Zugriff auf die Daten</li>
<li>Spark <strong>ML</strong>: Machine Learning</li>
<li>Spark <strong>GraphX</strong>: Graph-Verarbeitung</li>
</ul>
<hr>
<hr>
<h1 id="spark-in-docker-aufsetzen">Spark in Docker aufsetzen</h1>
<h2 id="dockerfile">Dockerfile</h2>
<pre class=" language-ssh"><code class="prism  language-ssh">FROM openjdk:8-alpine
RUN apk --update add wget tar bash
RUN wget http://artfiles.org/apache.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
RUN tar -xzf spark-2.4.4-bin-hadoop2.7.tgz &amp;&amp; \
    mv spark-2.4.4-bin-hadoop2.7 /spark &amp;&amp; \
    rm spark-2.4.4-bin-hadoop2.7.tgz

</code></pre>
<h2 id="powershell-in-windows">Powershell in Windows</h2>
<ul>
<li>Powershell öffnen</li>
<li>In Pfad des Dockerfile’s wechseln</li>
<li><code>docker build .</code></li>
<li><strong>ID</strong> des Builds aufschreiben oder Umbenennen</li>
<li><code>docker run --rm -it [ID] /bin/sh</code></li>
<li>In der Container-Shell den Spark Master starten</li>
<li><code>/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip `hostname` --port 7077 --webui-port 8080</code></li>
</ul>
</div>
</body>

</html>
